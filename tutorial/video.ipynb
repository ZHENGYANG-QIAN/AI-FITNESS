{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 导入工具包"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T05:53:32.036186200Z",
     "start_time": "2023-06-15T05:53:30.736765100Z"
    }
   },
   "outputs": [],
   "source": [
    "# mediapipe人工智能工具包\n",
    "import mediapipe as mp\n",
    "# opencv-python\n",
    "import cv2\n",
    "# 进度条库\n",
    "from tqdm import tqdm\n",
    "# 时间库\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 导入模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T05:53:32.069265600Z",
     "start_time": "2023-06-15T05:53:32.025031400Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入solution\n",
    "mp_pose = mp.solutions.pose\n",
    "# 导入绘图函数\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 导入模型\n",
    "pose = mp_pose.Pose(static_image_mode=False,  # 是静态图片还是连续视频帧\n",
    "                    model_complexity=2,  # 选择人体姿态关键点检测模型，0性能差但快，2性能好但慢，1介于两者之间\n",
    "                    smooth_landmarks=True,  # 是否平滑关键点\n",
    "                    enable_segmentation=True,  # 是否人体抠图\n",
    "                    min_detection_confidence=0.5,  # 置信度阈值\n",
    "                    min_tracking_confidence=0.5)  # 追踪阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 处理单帧的函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T05:53:32.076318400Z",
     "start_time": "2023-06-15T05:53:32.063689100Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_frame(img):\n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "    # 获取图像宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    # BGR转RGB\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # 将RGB图像输入模型获取预测结果\n",
    "    results = pose.process(img_RGB)\n",
    "    # 若检测出人体关键点\n",
    "    if results.pose_landmarks:\n",
    "        # 可视化关键点及骨架连线\n",
    "        mp_drawing.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        for i in range(33):  # 遍历所有33个关键点，可视化\n",
    "            # 获取该关键点的三维坐标\n",
    "            cx = int(results.pose_landmarks.landmark[i].x * w)\n",
    "            cy = int(results.pose_landmarks.landmark[i].y * h)\n",
    "            cz = results.pose_landmarks.landmark[i].z\n",
    "\n",
    "            # 关节点处圆点半径\n",
    "            radius = 5\n",
    "\n",
    "            if i == 0:  # 鼻尖\n",
    "                img = cv2.circle(img, (cx, cy), radius, (0, 0, 255), -1)\n",
    "            elif i in [11, 12]:  # 肩膀\n",
    "                img = cv2.circle(img, (cx, cy), radius, (223, 155, 6), -1)\n",
    "            elif i in [23, 24]:  # 髋关节\n",
    "                img = cv2.circle(img, (cx, cy), radius, (1, 240, 255), -1)\n",
    "            elif i in [13, 14]:  #胳膊时\n",
    "                img = cv2.circle(img, (cx, cy), radius, (140, 47, 240), -1)\n",
    "            elif i in [25, 26]:  # 膝盖\n",
    "                img = cv2.circle(img, (cx, cy), radius, (0, 0, 255), -1)\n",
    "            elif i in [15, 16, 27, 28]:  # 手腕和脚踝\n",
    "                img = cv2.circle(img, (cx, cy), radius, (223, 155, 60), -1)\n",
    "            elif i in [17, 19, 21]:  #左手\n",
    "                img = cv2.circle(img, (cx, cy), radius, (94, 218, 121), -1)\n",
    "            elif i in [18, 20, 22]:  #右手\n",
    "                img = cv2.circle(img, (cx, cy), radius, (16, 144, 247), -1)\n",
    "            elif i in [27, 29, 31]:  #左脚\n",
    "                img = cv2.circle(img, (cx, cy), radius, (29, 123, 243), -1)\n",
    "            elif i in [28, 30, 32]:  #右脚\n",
    "                img = cv2.circle(img, (cx, cy), radius, (193, 182, 255), -1)\n",
    "            elif i in [9, 10]:  #嘴\n",
    "                img = cv2.circle(img, (cx, cy), radius, (205, 235, 255), -1)\n",
    "            elif i in [1, 2, 3, 4, 5, 6, 7, 8]:  # 眼睛和脸颊\n",
    "                img = cv2.circle(img, (cx, cy), radius, (94, 218, 121), -1)\n",
    "            else:  #其它关键点\n",
    "                img = cv2.circle(img, (cx, cy), radius, (0, 255, 0), -1)\n",
    "    else:  # 未检测到人\n",
    "        scaler = 1\n",
    "        failure_str = 'No Person'\n",
    "        img = cv2.putText(img, failure_str, (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler,\n",
    "                          (255, 255, 255), 1)\n",
    "\n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1 / (end_time - start_time)\n",
    "    scaler = 1\n",
    "    # 在图像上写FPS数值，参数依次为: 图片，添加的文字，左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "    img = cv2.putText(img, 'FPS' + str(int(FPS)), (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler,\n",
    "                      (255, 255, 255), 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 视频逐帧处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T05:53:32.096231400Z",
     "start_time": "2023-06-15T05:53:32.076318400Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_video(input_path='example/jntm.mp4'):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = 'example/out-' + filehead\n",
    "    print('视频开始处理', input_path)\n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    print('视频总帧数为', frame_count)\n",
    "    # cv2.namedwindow('Crack Detection and Measurement Video Processing'\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH),\n",
    "                  cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    # fourcc= int(cap.get(cV2.CAP PROP FOURCC))# fourcc= cv2.VideoWriter fourcc(*'XVID')\n",
    "    # 创建了一个视频编码器对象 fourcc，其参数 'mp4v' 表示视频编码格式为 MPEG-4 编码器。该函数将返回一个用于指定输出视频编码格式的四字符码（fourcc）\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # 创建一个视频写入对象 out，其参数包括输出文件路径、视频编码器对象、帧率、视频尺寸等信息\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count - 1) as pbar:\n",
    "        try:\n",
    "            while cap.isOpened():\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "                try:\n",
    "                    frame = process_frame(frame)\n",
    "                except:\n",
    "                    print('error')\n",
    "                    pass\n",
    "\n",
    "                if success:\n",
    "                    out.write(frame)\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T05:56:38.011621200Z",
     "start_time": "2023-06-15T05:53:32.084159100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频开始处理 example/jntm.mp4\n",
      "视频总帧数为 1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [03:03<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频已保存 example/out-jntm.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_video(input_path='example/jntm.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
